{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56622439-ada1-4281-b2de-fc24812b9603",
   "metadata": {
    "name": "Introduction",
    "collapsed": false,
    "resultHeight": 271
   },
   "source": "## Reflection Pattern for LLM\nThis notebook demostrates the Reflection pattern for LLMs as defined by Andrew Ng of DeepLearning.ai.  The goal is to show how to prompt an LLM, have another prompt \"reflect\" on the answer, and incorporate the revisions from the reflection.\n\nThis examples demostrates how to generate python code for a Merge Sort (Classic Sorting Algo)."
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "import_packages",
    "collapsed": false,
    "resultHeight": 0,
    "codeCollapsed": false
   },
   "source": "# Import python packages\nimport streamlit as st\nimport pandas as pd\nfrom IPython.display import display_markdown\n\nfrom snowflake.cortex import Complete\nimport snowflake.snowpark.functions as F\nimport snowflake.snowpark.types as T\n\n# We can also use Snowpark for our analyses!\nfrom snowflake.snowpark.context import get_active_session\nsession = get_active_session()\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "d71f3412-3b66-4b3a-a5b3-6b0e640d5aa0",
   "metadata": {
    "language": "python",
    "name": "build_prompt_structure",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "def build_prompt_structure (prompt: str, role: str, tag: str = \"\") -> dict:\n    \"\"\"\n    Builds a structured prompt that includes the role and content.\n\n    Args:\n        prompt (str): The actual content of the prompt.\n        role (str): The role of the speaker (e.g., user, assistant).\n\n    Returns:\n        dict: A dictionary representing the structured prompt.\n    \"\"\"\n    if tag:\n        prompt = f\"<{tag}>{prompt}</{tag}>\"\n    return {\"role\": role, \"content\": prompt}",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "72baaf46-691b-4860-a008-570572c77a91",
   "metadata": {
    "language": "python",
    "name": "build_prompt_structure_test",
    "collapsed": true,
    "resultHeight": 245,
    "codeCollapsed": true
   },
   "outputs": [],
   "source": "build_prompt_structure(prompt = \"write  merge sort algorithm in python\", role = \"user\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a50b3317-b13a-42a9-a322-40aadeebc09b",
   "metadata": {
    "language": "python",
    "name": "cell1",
    "collapsed": false,
    "resultHeight": 195
   },
   "outputs": [],
   "source": "query = st.text_area(\"Enter your prompt:\",\"Generate a Python implementation of the Merge Sort algorithm\", \n                     height=150)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dd059c7d-ad12-4804-b444-9808405767f8",
   "metadata": {
    "language": "python",
    "name": "review_prompt",
    "collapsed": false,
    "resultHeight": 38,
    "codeCollapsed": true
   },
   "outputs": [],
   "source": "print (query)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f6ca5412-6bed-44b7-a89a-d29ab490d3eb",
   "metadata": {
    "language": "python",
    "name": "prompts",
    "resultHeight": 118,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "generation_chat_history = [\n    {\n        \"role\": \"system\",\n        \"content\": \"You are a Python programmer tasked with generating high quality Python code.\"\n        \"Your task is to Generate the best content possible for the users request. If the user provides critique,\" \n        \"respond with a revised version of your previous attempt.\"\n    }\n]\ngeneration_chat_history.append(\n    {\n        \"role\": \"user\",\n        \"content\": query\n    }\n)\n\nst.markdown (generation_chat_history)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5a15c2e0-ce1f-4062-9201-98934ec3a129",
   "metadata": {
    "language": "python",
    "name": "generate_mergesort_code",
    "collapsed": false,
    "resultHeight": 0,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "mergesort_code = Complete ('llama3.1-405b', generation_chat_history)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a330ba0f-120f-4c47-ae69-e732d4db5c3b",
   "metadata": {
    "language": "python",
    "name": "cell4",
    "collapsed": false,
    "resultHeight": 2366,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "st.markdown(mergesort_code)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1ad0566f-f38e-4be6-9070-9634c65d8970",
   "metadata": {
    "language": "python",
    "name": "update_generation_chat_history",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "generation_chat_history.append(\n    {\n        \"role\": \"assistant\",\n        \"content\": mergesort_code\n    }\n)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1c722f14-ccd8-430c-8e68-e82788a29f80",
   "metadata": {
    "language": "python",
    "name": "print_chat_history",
    "collapsed": false,
    "resultHeight": 44,
    "codeCollapsed": true
   },
   "outputs": [],
   "source": "print (generation_chat_history)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "28f95f5d-c93d-4926-a29d-ef402182b913",
   "metadata": {
    "language": "python",
    "name": "create_relfection_chat",
    "collapsed": false,
    "resultHeight": 0,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "reflection_chat_history = [\n    {\n        \"role\":\"system\",\n        \"content\" : \"You are Andrej Karpathy, an experienced computer scientist. You are tasked with generating critique and recommendations for the user code. If unit test are not, present suggest to create unit tests\"\n    }\n]",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1ecd2572-19b3-4831-9cf3-e3dcf1b351ad",
   "metadata": {
    "language": "python",
    "name": "append_reflection_chat",
    "collapsed": false,
    "resultHeight": 44,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "reflection_chat_history.append (\n    {\n        \"role\":\"user\",\n        \"content\": mergesort_code\n    }\n)\nprint (reflection_chat_history)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b1fbb69f-bca6-4e78-9b29-378dbfc85d74",
   "metadata": {
    "language": "python",
    "name": "generate_critique",
    "resultHeight": 0,
    "collapsed": false,
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "critique = Complete ('llama3.1-405b', reflection_chat_history)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "51355e94-60dd-405a-b3e7-0ce8f03f5eaf",
   "metadata": {
    "language": "python",
    "name": "critique_results",
    "collapsed": false,
    "resultHeight": 3134
   },
   "outputs": [],
   "source": "st.markdown (critique)\n",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "692cf3f4-beab-42ff-b325-6403b2da222f",
   "metadata": {
    "name": "incorporate_critique",
    "collapsed": false,
    "resultHeight": 127
   },
   "source": "## Incorporat the critique\nThe next step is to update the merge_code with the critique from our computer scientist.\nThen display the final implementaiton."
  },
  {
   "cell_type": "code",
   "id": "4e3de262-c234-4bc4-854c-9dbcb9e1d3e0",
   "metadata": {
    "language": "python",
    "name": "append_critique",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "generation_chat_history.append(\n    {\n        \"role\": \"user\",\n        \"content\": critique\n    }\n)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6b28fa9b-c87d-45e6-8f3e-db798ac64d9b",
   "metadata": {
    "language": "python",
    "name": "complete_critique",
    "collapsed": false,
    "resultHeight": 0
   },
   "outputs": [],
   "source": "essay = Complete ('llama3.1-405b', generation_chat_history)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2b260ea3-cac6-4f0f-8a22-345b111aedb5",
   "metadata": {
    "language": "python",
    "name": "display_final_result",
    "collapsed": false,
    "resultHeight": 3352
   },
   "outputs": [],
   "source": "st.markdown(essay)",
   "execution_count": null
  }
 ]
}